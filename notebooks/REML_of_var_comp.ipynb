{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: REML estimation of variance components\n",
    "\n",
    "Theo Meuwissen\n",
    "\n",
    "## Sire model\n",
    "The data **y** are affected by:\n",
    "- a sire effect (10 independent sires), \n",
    "- a herd effect (2 herd effects)\n",
    "- an independent residual effect (contains genetic effects of dam and Mendelian sampling + environmental effect)\n",
    "\n",
    "The model: $\\mathbf{y = Xb + Zu + e}$\n",
    "- **b**: herd effect (2 herds)\n",
    "- **u**: sire effect (10 sires)\n",
    "- **e**: residual effect (for 100 offspring)\n",
    "\n",
    "- heritability is $h^2 = 0.40$ \n",
    "- sire variance is $\\sigma_s^2 = 0.10$\n",
    "- residual variance is $\\sigma_e^2 = 0.90$\n",
    "\n",
    "\n",
    "## Simulate some sire model data\n",
    "- 10 sires with 10 offspring each\n",
    "- 2 herds: uneven offspringIDs in Herd1; even offspringIDs in Herd2\n",
    "- note: since data are randomly sampled: repetition of results below will give different answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Float64}:\n",
       " -3.2262439771102085\n",
       " -0.2177688288830595\n",
       " -3.827017463990323\n",
       " -1.2792352608621251\n",
       " -2.737852558391992\n",
       " -0.7277420972205069\n",
       " -2.1654699585908057\n",
       " -1.4147880205783288\n",
       " -2.490579920302945\n",
       " -1.150446633643876\n",
       " -2.487150159344688\n",
       "  0.2802919595222342\n",
       " -1.8038714657700716\n",
       "  ⋮\n",
       " -4.993811034587874\n",
       "  0.3531092900475421\n",
       " -2.48854795349344\n",
       "  1.2883891564009315\n",
       " -2.2029802357118777\n",
       "  1.6799085370077984\n",
       " -3.161570119614587\n",
       " -0.36463698145418966\n",
       " -4.2294749096553135\n",
       " -0.6952472931789662\n",
       " -2.1232873012997238\n",
       "  0.8087860951169439"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "s2=0.10\n",
    "e2=0.90\n",
    "q=10                       # number of sires\n",
    "nd=10                      # daughters per sire\n",
    "n=q*nd                     # total number of records\n",
    "b=randn(2)\n",
    "u=randn(q)*sqrt(s2)       # ~N(0,s2)\n",
    "e=randn(n)*sqrt(e2)      # ~N(0,e2)\n",
    "X=kron(ones(Int(n/2),1),I(2))    #design matrix for herd (kron=kronecker product)\n",
    "Z=kron(I(q),ones(nd,1))   #design matrix for sire\n",
    "y=X*b+Z*u+e                #the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation by  EM - REML\n",
    "We use true values of variance components as starting values.\n",
    "- slides 5 and 5 of estimation_of_variance_components.ppt\n",
    "- note: the same BLUP solutions and PEV are obtained by the usual Mixed Model Equations incl. fixed effects\n",
    "- note2: no A-inverse is needed here because sires are unrelated \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Matrix{Float64}:\n",
       " 0.110114  0.968879"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=I(100)-X*inv(X'*X)*X'                  # the projection matrix S: S*y = residuals after fitting herd\n",
    "lambda=e2/s2                             #sire model lambda = ratio of residual to sire variance\n",
    "MMM=Z'*S*Z+I(10)*lambda                  #Mixed Model equation matrix (after absorption of fixed effects)\n",
    "uhat=inv(MMM)*Z'*S*y                     #BLUP solution of sire effects\n",
    "s2hat=(uhat'*uhat+tr(inv(MMM)*e2))/q     #update of sire variance\n",
    "bhat=inv(X'*X)*(X'*y-X'*Z*uhat)           # from usual Mixed Model Equations (fixed effect part)\n",
    "ehat=y-X*bhat-Z*uhat                      #estimate of residuals\n",
    "e2hat=(ehat'*ehat+tr(inv(MMM)*Z'*Z)*e2)/n #update of error variance\n",
    "[s2hat e2hat]                              #show results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation by Average Information - REML\n",
    "Again use true values of variance components as starting values (note: iterative algorithms need starting values and good starting values help convergence (especially for AI-REML)).\n",
    "- slide 8 of estimation_of_variance_components.ppt shows calculation of Score functions\n",
    "- slide 9 shows calculation of second derivatives\n",
    "- again: no A-inverse is needed here because sires are assumed unrelated\n",
    "- slide 7 in Maximum_likelihood_estimation.ppt gives formula for update in 2nd order algorithms (average info)\n",
    "- note: P is calculated directly below, but it is more efficient to calculate terms like d'*P*d for any d (but treating d as records), as d'*P*d = (d-Xh)'*inv(V)*(d-Xh) = d'*inv(R)*ehat, where h=estimate of fixed effects IF d were actual records, and ehat=estimates of residuals if d were records. The latter is only requires estimation of BLUP solutions given d as records, not the inversion of V.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.09081008934116064\n",
       " 0.8247537664543426"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V=Z*Z'*s2+I(n)*e2                #(co)variance matrix of records\n",
    "VI=inv(V)\n",
    "P=VI-VI*X*inv(X'*VI*X)*X'*VI     #Projection matrix\n",
    "Score=zeros(2)                   #Initialise Score vector of dimension 2 since there are 2 variance components\n",
    "Score[1]=-0.5*(q/s2-tr(inv(MMM))*e2/(s2^2)-uhat'*uhat/(s2^2))\n",
    "Score[2]=-0.5*((n-q)/e2-tr(inv(MMM))*lambda/e2-ehat'*ehat/(e2^2))\n",
    "AI=zeros(2,2)                      # (2x2) Average Information Matrix of second derivatives\n",
    "AI[1,1]=uhat'*Z'*P*Z*uhat/(s2^2)\n",
    "AI[2,2]=ehat'*P*ehat/(e2^2)\n",
    "AI[1,2]=ehat'*P*Z*uhat/(e2*s2)\n",
    "AI[2,1]=AI[1,2]                     \n",
    "update=-inv(AI)*Score            # =(theta - theta0)\n",
    "theta=[s2; e2] + update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "- both AI-REML and EM-REML are iterative algorithms\n",
    "- this implies that after updated estimates are obtained, BLUP solutions are recalculated and new updates are calculated until the changes in solutions become negligibly small (the algorithm converges)\n",
    "- the AI algorithm may never converge. The EM algorithm is guaranteed to converge, but it may be slow. If the AI algorithm does not converge, one may try some iterations of the EM algorithm.\n",
    "- also: we need (good) starting values for the variance components to start the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-DEV",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
